from abc import ABC, abstractmethod 
from sklearn.pipeline import Pipeline, make_pipeline
from category_encoders.woe import WOEEncoder
from sklearn.base import BaseEstimator
import numpy as np
import pandas as pd

# from functools import reduce
import transform as trf

#---------------------------------------------------------------------
# pipelines
#---------------------------------------------------------------------
# TORM: for numerical variables
num_pipeline = Pipeline([
    ('selector', trf.TypeSelector("numerical")),
    ('std_scaler', trf.Scaler()),
])

# TORM: for categorical and binary variables
categorical_pipeline = Pipeline([
    ('selector', trf.TypeSelector("factor")),
    ('dummy_encoder', trf.DummyEncoder()),
])

# for numerical type of variables
numeric_pipeline = Pipeline([
    ('selector', trf.DTypeSelector("object", True)),
    ('std_scaler', trf.Scaler()),
])

# for object (string) type of variables
object_pipeline = Pipeline([
    ('selector', trf.DTypeSelector("object")),
    ('dummy_encoder', trf.DummyEncoder()),
])


def make_base_pipeline(target_col, exclusions=[]):
    """Basic variable transformation
    
        Parameters
        ----------
        target_col : string
        exclusions : string
    
        Returns 
        ----------
        df
    """
    base_pipeline = Pipeline([
        ('upper_case', trf.UpperCaseColumn()),
        ('drop_columns', trf.DropColumns(exclusions + [target_col])),
        ('imputer', trf.DataFrameImputer()),
    ])
    return base_pipeline

def make_feature_pipeline(ntransformer, ctransformer, target_col, exclusions=[]):
    """hybrid feature transformation
    
        Parameters
        ----------
        ntransformer : transformer for numeric variable
        ctransformer : transformer for sring (object) variable
        target_col : string
        exclusions : string
    
        Returns 
        ----------
        df
    """
    base_pipeline = make_base_pipeline(target_col, exclusions)
    pipeline = Pipeline([
        ('base_pipeline', base_pipeline),
        ('transformer', trf.HybridTransformer(ntransformer, ctransformer))
    ])
    return pipeline

def make_dummy_pipeline(target_col, exclusions=[]):
    """feature variable transformation
    
        Parameters
        ----------
        ntransformer : transformer for numeric variable
        ctransformer : transformer for sring (object) variable
        target_col : string
        exclusions : string
    
        Returns 
        ----------
        df
    """
    base_pipeline = make_base_pipeline(target_col, exclusions)
    pipeline = Pipeline([
        ('base_pipeline', base_pipeline),
        ('seq_transformer', trf.SequentialTransformer([numeric_pipeline, object_pipeline])),
        ('combiner', trf.Combiner()),
    ])
    return pipeline

def make_target_pipeline(target_name, mapping=None):
    """extract and transform target variable

        to get component from pipeline: e.g. dpy.steps[1][1].encoder
    
        Parameters
        ----------
        target_name : string
        mapping : dictionary of custom mapping (optional)
    
        Returns 
        ----------
        ndarray 
    """
    return Pipeline([
        ('upper_case', trf.UpperCaseColumn()),
        ('encoder', trf.TargetEncoder(target_name, mapping))
    ])

def make_target_guided_pipeline(name, transformer, y):
    return Pipeline([
        (name, trf.SupervisedTransformer(transformer(),y))
    ])


def make_classification_pipeline(pipelines, target_col, exclusions=[]):
    """add custom pipeline in additional to basic
    
        Parameters
        ----------
        pipelines : list of additional pipelines
        target_col : string
        exclusions : string
    
        Returns 
        ----------
        df
    """
    base_pipeline = make_base_pipeline(target_col, exclusions)
    px =[('base_pipeline', base_pipeline)]
    px = px + pipelines 
    px = px + [('std_scaler', trf.Scaler())]
    px = Pipeline(px)
    return px

# ------------------------------------------------------------
# Process
# ------------------------------------------------------------
# TORM
def get_target_mappings(py, idx=1):
    """Get target transform map

        Parameters
        ----------
        py is generated by make_target_pipeline
    """

    # label encoder
    # encoder = py.steps[1][1].encoder
    encoder = py[idx].encoder
    return dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))

# TORM
def dummy_feature_preprocess(df, target_col, exclusions=[], mapping=None):
    """Preprocessing Raw data
    
        Parameters
        ----------
        df : raw data frame
        target_col : string
        mapping : custom target variable transformation map
    
        Returns 
        ----------
        df
    """
    # extract target column
    py = make_target_pipeline(target_col, mapping)
    y = py.fit_transform(df)

    # extract and transform feature
    px = make_dummy_pipeline(target_col, exclusions)
    df = px.fit_transform(df)

    X = df.to_numpy()

    return (X, y, df.columns, py, px)


# TORM
def binary_classfication_preprocess(df, target_col, exclusions=[], mapping=None):
    """Preprocessing Raw data
    
        Parameters
        ----------
        df : raw data frame
        target_col : string
        exclusions : list of names to be excluded
        mapping : custom target variable transformation map
    
        Returns 
        ----------
        X : explantory variables
        y : target column
        feature : list of feature names
        py : target variable pipeline
        px : feature variable pipeline
    """

    # extract target column
    py = make_target_pipeline(target_col, mapping)
    y = py.fit_transform(df)

    # for target guided pipeline, need the target y
    # TODO: add more here
    woe_transformer = make_target_guided_pipeline('WOE', WOEEncoder, y)
    pipelines = [('WOE', woe_transformer)]
    px = make_classification_pipeline(pipelines, target_col, exclusions)

    # note that px produces a data frame while X is a ndarray
    df = px.fit_transform(df, y)
    X = df.to_numpy()

    return (X, y, df.columns, py, px)

# TORM
def standard_feature_preprocess(df, target_col, ntransformer, ctransformer, exclusions=[], mapping=None):
    """Preprocessing Raw data
    
        Parameters
        ----------
        df : raw data frame
        target_col : string
        ntransformer: transformer for numeric variables (must act on numpy, e.g. StandardScaler)
        ctransformer: transformer for categorical variables (must act on numpy, e.g. OrdinalEncoder)
        mapping : custom target variable transformation map
    
        Returns 
        ----------
        X : explantory variables
        y : target column
        feature : list of feature names
        py : target variable pipeline
        px : feature variable pipeline
    """

    # extract target column
    py = make_target_pipeline(target_col, mapping)
    y = py.fit_transform(df)

    # extract and transform feature
    px = make_feature_pipeline(ntransformer, ctransformer, target_col, exclusions)
    # note that px produces a data frame while X is a ndarray
    df = px.fit_transform(df)
    X = df.to_numpy()

    return (X, y, df.columns, py, px)

# ------------------------------------------------------------
# Pipeline class
# ------------------------------------------------------------
class Pipe(ABC):
    """Base class for transformation pipeline

        Parameters
        -------
        target_col : column name of the target
        exclusions : list of columns to be excluded
        mapping : if not given, target is assumed to be encoded as 1
    
    """

    def __init__(self, target_col, exclusions=[], mapping=None):
        self.features = None
        self.X = None
        self.y = None
        self.px = None
        self.py = None
        self.mapping = mapping
        self.exclusions = exclusions
        self.target_col= target_col

    def feature_names(self):
        return self.features

    def pipelines(self):
        return (self.px, self.py)

    def out(self):
        return (self.X, self.y)

    def __get_target_mappings(self, idx=1):
        """Get target transform map

            Parameters
            ----------
            py is generated by make_target_pipeline
        """

        # label encoder
        encoder = self.py[idx].encoder
        return dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))

    def target_mapping(self):
        return self.mapping

    def assign_mapping(self, idx=1):
        """
            idx : label encoder for the target pipeline
        """
        # assign mapping
        if self.mapping is None:
            self.mapping = self.__get_target_mappings(idx)

    @abstractmethod
    def process(self, df, **kwargs):
        """
            Parameters
            ----------
            df : data frame
            **kwargs: dict (Additional parameters)

            Assignment
            --------
            py : pipeline for target variable
            y  : target variable
            px : pipeline for feature variable
            X  : feature variables
            mapping : target variable encode map
            features : list of feature names
        """
        pass

class StandardPipeline(Pipe):
    """
        Parameters for process()
        ----------
        ntransformer : transformer for numerical variables
        ctransformer : transformer for categorical variables
    """

    def process(self, df, **kwargs):  
        self.py = make_target_pipeline(self.target_col, self.mapping)
        self.y = self.py.fit_transform(df)

        # assign mapping
        self.assign_mapping()

        # extract and transform feature
        ntransformer = kwargs["ntransformer"]
        ctransformer = kwargs["ctransformer"]
        self.px = make_feature_pipeline(ntransformer, ctransformer, self.target_col, self.exclusions)

        # note that px produces a data frame while X is a ndarray
        sdf = self.px.fit_transform(df)
        self.X = sdf.to_numpy()
        self.features = sdf.columns

class DummyPipeline(Pipe):
    """Create Dummy variables for all categorical Variables
    """

    def process(self, df, **kwargs):  
        self.py = make_target_pipeline(self.target_col, self.mapping)
        self.y = self.py.fit_transform(df)

        # assign mapping
        self.assign_mapping()

        self.px = make_dummy_pipeline(self.target_col, self.exclusions)

        # note that px produces a data frame while X is a ndarray
        sdf = self.px.fit_transform(df)
        self.X = sdf.to_numpy()
        self.features = sdf.columns

class WoEPipeline(Pipe):
    """WOE transform all categorical Variables
        for binary target only
    """

    def process(self, df, **kwargs):  
        self.py = make_target_pipeline(self.target_col, self.mapping)
        self.y = self.py.fit_transform(df)

        # assign mapping
        self.assign_mapping()

        # add WOE to basic pipeline
        woe_transformer = make_target_guided_pipeline('WOE', WOEEncoder, y)
        pipelines = [('WOE', woe_transformer)]
        self.px = make_classification_pipeline(pipelines, self.target_col, self.exclusions)

        # note that px produces a data frame while X is a ndarray
        sdf = self.px.fit_transform(df)
        self.X = sdf.to_numpy()
        self.features = sdf.columns